[
  {
    "objectID": "jan20.html",
    "href": "jan20.html",
    "title": "Variance of Dice",
    "section": "",
    "text": "First, note that we may use the sample data from an arbitrary discrete distribution with relatively small support. Read help(sample) for more, but the basic gist is that we give it the support x, the size (number of samples), a boolean replace which tells us if we sample with replacement or not (we will almost always use TRUE here since we want our samples to be independent), and prob is essentially the probability mass function. In particular, the first element of prob is the probability of the first element of x, the second element of prob is the probability of the second element of x and so on. We construct x and prob using the “combine” function c. Note that we may omit prob if the distribution is uniform. In other words, the following are equivalent:\nsample(c(1, 2, 3, 4, 5, 6), 2, replace = TRUE, c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))\nsample(c(1, 2, 3, 4, 5, 6), 2, replace = TRUE)\nWe used the longer version in class, but we’ll use the shorter version in this document."
  },
  {
    "objectID": "jan20.html#sampling",
    "href": "jan20.html#sampling",
    "title": "Variance of Dice",
    "section": "",
    "text": "First, note that we may use the sample data from an arbitrary discrete distribution with relatively small support. Read help(sample) for more, but the basic gist is that we give it the support x, the size (number of samples), a boolean replace which tells us if we sample with replacement or not (we will almost always use TRUE here since we want our samples to be independent), and prob is essentially the probability mass function. In particular, the first element of prob is the probability of the first element of x, the second element of prob is the probability of the second element of x and so on. We construct x and prob using the “combine” function c. Note that we may omit prob if the distribution is uniform. In other words, the following are equivalent:\nsample(c(1, 2, 3, 4, 5, 6), 2, replace = TRUE, c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))\nsample(c(1, 2, 3, 4, 5, 6), 2, replace = TRUE)\nWe used the longer version in class, but we’ll use the shorter version in this document."
  },
  {
    "objectID": "jan20.html#sample-variance-of-2d6",
    "href": "jan20.html#sample-variance-of-2d6",
    "title": "Variance of Dice",
    "section": "Sample Variance of 2d6",
    "text": "Sample Variance of 2d6\nRecall our goal: to find the sample variance \\(S^2\\) of 2d6, i.e, of i.i.d. random variables \\(X_1,X_2\\) with the uniform distribution on \\(\\{1,2,3,4,5,6\\}\\).\nIn class, we found that the probability mass function of \\(S^2\\) is \\[\nf_{S^2}(x) = \\begin{cases}\n\\frac{1}{6} &\\text{if }x = 0 \\\\\n\\frac{5}{18} &\\text{if }x = \\frac{1}{2} \\\\\n\\frac{2}{9} &\\text{if }x = 2 \\\\\n\\frac{1}{6} &\\text{if }x = \\frac{9}{2} \\\\\n\\frac{1}{9} &\\text{if }x = 8 \\\\\n\\frac{1}{18} &\\text{if }x = \\frac{25}{2} \\\\\n0 &\\text{otherwise.}\n\\end{cases}\n\\]\nand that \\(E(S^2) = \\frac{35}{12}\\), which happens to be equal to \\(\\operatorname{Var}(X_i)\\)."
  },
  {
    "objectID": "jan20.html#monte-carlo-simulations",
    "href": "jan20.html#monte-carlo-simulations",
    "title": "Variance of Dice",
    "section": "Monte Carlo Simulations",
    "text": "Monte Carlo Simulations\nFirst, let’s check the expected value. Recall that to perform a Monte Carlo simulation, we use mean(replicate(...)) to run our code a bunch of times and find the average value.\n\nmean(replicate(10000, var(sample(c(1, 2, 3, 4, 5, 6), 2, replace = TRUE))))\n\n[1] 2.9941\n\n35/12\n\n[1] 2.916667\n\n\nNow let’s check the values of our probability mass function. Recall that by have a statement (e.g., var(...) == 0), replicate(...) spits out a bunch of booleans (TRUE and FALSE), and mean(...) gives us the proportion of TRUE’s. This gives us an estimate of the probability of that particular value.\n\nmean(replicate(10000, var(sample(c(1, 2, 3, 4, 5, 6), 2, replace = TRUE)) == 0))\n\n[1] 0.1654\n\n1/6\n\n[1] 0.1666667\n\n\n\nmean(replicate(10000, var(sample(c(1, 2, 3, 4, 5, 6), 2, replace = TRUE)) == 1/2))\n\n[1] 0.2742\n\n5/18\n\n[1] 0.2777778\n\n\n\nmean(replicate(10000, var(sample(c(1, 2, 3, 4, 5, 6), 2, replace = TRUE)) == 2))\n\n[1] 0.2219\n\n2/9\n\n[1] 0.2222222\n\n\n\nmean(replicate(10000, var(sample(c(1, 2, 3, 4, 5, 6), 2, replace = TRUE)) == 9/2))\n\n[1] 0.1641\n\n1/6\n\n[1] 0.1666667\n\n\n\nmean(replicate(10000, var(sample(c(1, 2, 3, 4, 5, 6), 2, replace = TRUE)) == 8))\n\n[1] 0.1091\n\n1/9\n\n[1] 0.1111111\n\n\n\nmean(replicate(10000, var(sample(c(1, 2, 3, 4, 5, 6), 2, replace = TRUE)) == 25/2))\n\n[1] 0.0546\n\n1/18\n\n[1] 0.05555556"
  },
  {
    "objectID": "jan20.html#binomial-distribution",
    "href": "jan20.html#binomial-distribution",
    "title": "Variance of Dice",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\nWe also started a second problem. Suppose \\(X_1,X_2\\sim B\\left(3, \\frac{1}{2}\\right)\\). We computed\n\\[\\begin{align}\nP(S^2 = 0) &= \\sum_{k=0}^3 P(X_1 = k)P(X_2=k) \\\\\n&= \\sum_{k=0}^3\\left(\\binom{3}{k}\\left(\\frac{1}{2}\\right)^k\\left(\\frac{1}{2}\\right)^{3-k}\\right)^2 \\\\\n&= \\sum_{k=0}\\binom{3}{k}^2\\frac{1}{64}\\\\\n&= \\frac{1}{64}\\left(1^2 + 3^2 + 3^2 + 1^3\\right) \\\\\n&= \\frac{5}{16}\n\\end{align}\\]\nLet’s check this with a Monte Carlo simulation as well. We may use the rbinom function. It takes three arguments: the number of samples and then the \\(n\\) and \\(p\\) from our binomial distribution. So we want to use rbinom(2, 3, 1/2).\n\nmean(replicate(10000, var(rbinom(2, 3, 1/2)) == 0))\n\n[1] 0.3102\n\n5/16\n\n[1] 0.3125"
  },
  {
    "objectID": "jan13.html",
    "href": "jan13.html",
    "title": "Monte Carlo Simulations",
    "section": "",
    "text": "Recall that we found that if \\(X_1, X_2\\sim U(0, 1)\\), then the minimum \\(X_{(1)}\\) has probability density function \\(f_{X_{(1)}}(x) = 2(1-x)\\). Integrating, its cumulative distribution function (on the unit interval) is \\[\\begin{align}\nF_{X_{(1)}}(x) &= \\int_0^x 2(1 - t)\\,dt \\\\\n&= -(1-t)^2\\Big|_0^x \\\\\n&= -(1-x)^2 + (1 - 0)^2 \\\\\n&= -1 + 2x - x^2 + 1 \\\\\n&= -x^2 + 2x\n\\end{align}\\]\nLet’s check this with some Monte Carlo simulations. For example, we should expect that the probability that our minimum is less than \\(\\frac{1}{2}\\) is\n\\[F_{X_{(1)}}(0.5) = -0.5^2 + 2\\cdot 0.5 = 0.75\\]\nRecall that runif(2) will generate a random sample from our, and min(runif(2)) will give us the minimum. We can do this multiple times with replicate:\n\nreplicate(10, min(runif(2)))\n\n [1] 0.3034710 0.0725154 0.5560669 0.1796919 0.2305097 0.6376396 0.2744835\n [8] 0.3586434 0.8814961 0.6673324\n\n\nWe’re interested in finding the number of our random samples that were less than 0.5. If we replicate a statement, we’ll get a list of a bunch of boolean (TRUE or FALSE) objects.\n\nreplicate(10, min(runif(2)) &lt; 0.5)\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\nR treats these Boolean objects like integers (0 for FALSE and 1 for TRUE), so we can compute the proportion of TRUE’s by taking the mean:\n\nmean(replicate(10, min(runif(2)) &lt; 0.5))\n\n[1] 0.7\n\n\nNow let’s increase the sample size:\n\nmean(replicate(10000, min(runif(2)) &lt; 0.5))\n\n[1] 0.7498\n\n\nWe got pretty close to our theoretical result of 0.75!"
  },
  {
    "objectID": "jan15.html",
    "href": "jan15.html",
    "title": "Monte Carlo simulations for the beta distribution",
    "section": "",
    "text": "Recall that if \\(X\\) has the beta distribution with shape parameters \\(\\alpha\\) and \\(\\beta\\), i.e., \\(X\\sim\\operatorname{Beta}(\\alpha,\\beta)\\), then \\(X\\) has probability density function\n\\[f_X(x) = \\begin{cases}\n\\frac{1}{B(\\alpha)(\\beta)}x^{\\alpha - 1}(1 - x)^{\\beta - 1} & \\text{if }0 &lt; x &lt; 1 \\\\\n0 & \\text{otherwise,}\n\\end{cases}\n\\] where \\(B\\) is the beta function given by \\[B(\\alpha,\\beta) = \\int_0^1x^{\\alpha - 1}(1 - x)^{\\beta - 1}\\,dx = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}.\\]\nWe saw in class that if \\(X_1,X_2\\sim\\operatorname{Beta}(2, 1)\\), then their sample mean \\(\\overline X\\) has cumulative distribution function \\[\nF_{\\overline X}(z) = \\begin{cases}\n0 &\\text{if }z \\leq 0 \\\\\n\\frac{8}{3}z^4 &\\text{if } 0 &lt; z \\leq\\frac{1}{2} \\\\\n-\\frac{8}{3}z^4 + 8z^2 - \\frac{16}{3}z + 1 &\\text{if }\\frac{1}{2} &lt; z &lt; 1 \\\\\n1 &\\text{if }z \\geq 1\\\\\n\\end{cases}\n\\]"
  },
  {
    "objectID": "jan15.html#beta-distribution",
    "href": "jan15.html#beta-distribution",
    "title": "Monte Carlo simulations for the beta distribution",
    "section": "",
    "text": "Recall that if \\(X\\) has the beta distribution with shape parameters \\(\\alpha\\) and \\(\\beta\\), i.e., \\(X\\sim\\operatorname{Beta}(\\alpha,\\beta)\\), then \\(X\\) has probability density function\n\\[f_X(x) = \\begin{cases}\n\\frac{1}{B(\\alpha)(\\beta)}x^{\\alpha - 1}(1 - x)^{\\beta - 1} & \\text{if }0 &lt; x &lt; 1 \\\\\n0 & \\text{otherwise,}\n\\end{cases}\n\\] where \\(B\\) is the beta function given by \\[B(\\alpha,\\beta) = \\int_0^1x^{\\alpha - 1}(1 - x)^{\\beta - 1}\\,dx = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}.\\]\nWe saw in class that if \\(X_1,X_2\\sim\\operatorname{Beta}(2, 1)\\), then their sample mean \\(\\overline X\\) has cumulative distribution function \\[\nF_{\\overline X}(z) = \\begin{cases}\n0 &\\text{if }z \\leq 0 \\\\\n\\frac{8}{3}z^4 &\\text{if } 0 &lt; z \\leq\\frac{1}{2} \\\\\n-\\frac{8}{3}z^4 + 8z^2 - \\frac{16}{3}z + 1 &\\text{if }\\frac{1}{2} &lt; z &lt; 1 \\\\\n1 &\\text{if }z \\geq 1\\\\\n\\end{cases}\n\\]"
  },
  {
    "objectID": "jan15.html#monte-carlo-simulation",
    "href": "jan15.html#monte-carlo-simulation",
    "title": "Monte Carlo simulations for the beta distribution",
    "section": "Monte Carlo simulation",
    "text": "Monte Carlo simulation\nFirst, let’s define an R function to evaluate our cdf from above:\n\nF &lt;- function(z) {\n  if (z &lt;= 0) {\n    return(0)\n  } else if (z &lt;= 1/2) {\n    return(8/3 * z^4)\n  } else if (z &lt; 1 ) {\n    return (-8/3 * z^4 + 8*z^2 - 16/3*z + 1)\n  } else {\n    return(1)\n  }\n}\n\nNext, we can use R to generate a random sample of \\(\\overline X\\) by first using rbeta(2, 2, 1) to generate 2 random samples from a \\(\\operatorname{Beta}(2, 1)\\) distribution, and then mean to find their sample mean.\n\nmean(rbeta(2,2,1))\n\n[1] 0.7552967\n\n\nTo perform our Monte Carlo simulation, we use replicate to perform the process a bunch of times. Each time, we compare to some value, yielding TRUE or FALSE, and then mean to find the proportion of TRUE’s. (Since TRUE is treated like 1 and FALSE like 0.)\nLet’s choose several different choices for \\(z\\) and compare the theoretical results with our simulated results.\n\nz &lt;- 0.25\nF(z)\n\n[1] 0.01041667\n\nmean(replicate(10000, mean(rbeta(2,2,1)) &lt; z))\n\n[1] 0.011\n\n\n\nz &lt;- 0.5\nF(z)\n\n[1] 0.1666667\n\nmean(replicate(10000, mean(rbeta(2,2,1)) &lt; z))\n\n[1] 0.1676\n\n\n\nz &lt;- 0.75\nF(z)\n\n[1] 0.65625\n\nmean(replicate(10000, mean(rbeta(2,2,1)) &lt; z))\n\n[1] 0.6476\n\n\nNot bad!"
  },
  {
    "objectID": "jan8.html",
    "href": "jan8.html",
    "title": "Statistical Graphics",
    "section": "",
    "text": "Statistical Graphics\nWe will use the software platform R to do many computations.\nR comes with various builtin datasets to play around with.\n\nHairEyeColor\n\n, , Sex = Male\n\n       Eye\nHair    Brown Blue Hazel Green\n  Black    32   11    10     3\n  Brown    53   50    25    15\n  Red      10   10     7     7\n  Blond     3   30     5     8\n\n, , Sex = Female\n\n       Eye\nHair    Brown Blue Hazel Green\n  Black    36    9     5     2\n  Brown    66   34    29    14\n  Red      16    7     7     7\n  Blond     4   64     5     8\n\n\nThere are various ways to represent data visually using graphics. One example is a “mosaic plot”:\n\nmosaicplot(~ Eye + Sex, data=HairEyeColor)\n\n\n\n\n\n\n\n\nVisually, it appears that hair and eye color may be independent from sex, but eye and hair color may be dependent on each other.\nWe can import data sets using the scan function:\n\nspeed.of.light &lt;- scan(\"michelson1.d\")\nsort(speed.of.light)\n\n  [1]  620  650  720  720  720  740  740  740  750  760  760  760  760  760  770\n [16]  780  780  790  790  790  800  800  800  800  800  810  810  810  810  810\n [31]  810  810  810  810  810  820  820  830  830  840  840  840  840  840  840\n [46]  840  840  850  850  850  850  850  850  850  850  860  860  860  870  870\n [61]  870  870  880  880  880  880  880  880  880  880  880  880  890  890  890\n [76]  900  900  910  910  920  930  930  940  940  940  950  950  950  960  960\n [91]  960  960  970  980  980  980 1000 1000 1000 1070\n\nstem(speed.of.light)\n\n\n  The decimal point is 2 digit(s) to the right of the |\n\n   6 | 2\n   6 | 5\n   7 | 222444\n   7 | 566666788999\n   8 | 000001111111111223344444444\n   8 | 5555555566677778888888888999\n   9 | 0011233444\n   9 | 55566667888\n  10 | 000\n  10 | 7\n\n\n\nhist(speed.of.light)\n\n\n\n\n\n\n\n\nBased on these graphics, it appears that these measurements may come from a normal distribution.\n\nboxplot(speed.of.light)\n\n\n\n\n\n\n\n\n\nquantile(speed.of.light, c(0, 0.25, 0.5, 0.75, 1))\n\n    0%    25%    50%    75%   100% \n 620.0  807.5  850.0  892.5 1070.0 \n\n\n\nplot.ecdf(speed.of.light, ylab=\"F_n(x)\")\n\n\n\n\n\n\n\n\n\nhelp(plot.ecdf)"
  },
  {
    "objectID": "jan22.html",
    "href": "jan22.html",
    "title": "Computing various probabiltiies in R",
    "section": "",
    "text": "Suppose \\(Z_1,\\ldots,Z_5\\sim N(0,1)\\) are independent random variables. Let’s find the probability that \\(Z_1^2 + \\cdots + Z_5^2\\) is at least 3, i.e., \\(P(Z_1^2 + \\cdots + Z_5^2 &gt; 3)\\). This sum has distribution \\(\\chi^2(5)\\). So if \\(W\\sim \\chi^2(5)\\), we can use \\(P(W &gt; 3) = 1 - P(W \\leq 3)\\).\nIn R, if we want to compute values of the cumulative distribution function of a particular distribution, we use a function beginning with p. In the case of the chi-squared distribution, that function is pchiqsq. In general if \\(W\\sim\\chi^2(\\nu)\\) and we want to compute \\(P(W &lt; w)\\), we use pchiqsq(w, ν).\nSo in this case, we have:\n\n1 - pchisq(3, 5)\n\n[1] 0.6999858\n\n\nAlternatively, we can skip the 1 - and use the lower.tail = FALSE option to switch the direction of the inequality.\n\npchisq(3, 5, lower.tail = FALSE)\n\n[1] 0.6999858"
  },
  {
    "objectID": "jan22.html#chi-squared-distribution",
    "href": "jan22.html#chi-squared-distribution",
    "title": "Computing various probabiltiies in R",
    "section": "",
    "text": "Suppose \\(Z_1,\\ldots,Z_5\\sim N(0,1)\\) are independent random variables. Let’s find the probability that \\(Z_1^2 + \\cdots + Z_5^2\\) is at least 3, i.e., \\(P(Z_1^2 + \\cdots + Z_5^2 &gt; 3)\\). This sum has distribution \\(\\chi^2(5)\\). So if \\(W\\sim \\chi^2(5)\\), we can use \\(P(W &gt; 3) = 1 - P(W \\leq 3)\\).\nIn R, if we want to compute values of the cumulative distribution function of a particular distribution, we use a function beginning with p. In the case of the chi-squared distribution, that function is pchiqsq. In general if \\(W\\sim\\chi^2(\\nu)\\) and we want to compute \\(P(W &lt; w)\\), we use pchiqsq(w, ν).\nSo in this case, we have:\n\n1 - pchisq(3, 5)\n\n[1] 0.6999858\n\n\nAlternatively, we can skip the 1 - and use the lower.tail = FALSE option to switch the direction of the inequality.\n\npchisq(3, 5, lower.tail = FALSE)\n\n[1] 0.6999858"
  },
  {
    "objectID": "jan22.html#normal-distribution",
    "href": "jan22.html#normal-distribution",
    "title": "Computing various probabiltiies in R",
    "section": "Normal distribution",
    "text": "Normal distribution\nLet’s say \\(X_1,\\ldots,X_{10}\\sim N(1, 25)\\) are independent. (Note that this means \\(\\sigma^2 = 25\\) and so \\(\\sigma = 5\\).) Find the probability that \\(\\overline X\\) is less than 2.\nWe know that \\(\\dfrac{\\overline X - \\mu}{\\sigma/\\sqrt {n}}\\sim N(0,1)\\), and so if we say that \\(Z\\sim N(0,1)\\), then we have:\n\\[P(\\overline X &lt; 2) = P\\left(Z &lt; \\frac{2 - 1}{5/\\sqrt{10}}\\right) = P\\left(Z &lt; \\frac{\\sqrt{10}}{5}\\right)\\]\nWe can use the pnorm function to compute normal probabilities in R. In this case:\n\npnorm(sqrt(10)/5)\n\n[1] 0.7364554\n\n\nAlternatively, we can provide the mean and and standard deviation (of \\(\\overline X\\), so \\(\\frac{\\sigma}{\\sqrt n}\\)) as additional arguments to pnorm:\n\npnorm(2, 1, 5/sqrt(10))\n\n[1] 0.7364554"
  },
  {
    "objectID": "jan22.html#t-distribution",
    "href": "jan22.html#t-distribution",
    "title": "Computing various probabiltiies in R",
    "section": "\\(t\\)-distribution",
    "text": "\\(t\\)-distribution\nNow let’s say that instead of a population variance of 25, we have a sample variance of 25. In this case, since we don’t know \\(\\sigma^2\\), we can use the \\(t\\)-distribution. In particular, we have \\(\\dfrac{\\overline X - \\mu}{S/\\sqrt n} \\sim t(n - 1)\\).\nSo if \\(T\\sim t(9)\\), we can say that\n\\[P(\\overline X &lt; 2) = P\\left(T &lt; \\frac{2 - 1}{5/\\sqrt{10}}\\right) = P\\left(T &lt; \\frac{\\sqrt{10}}{5}\\right)\\]\nWe can use the pt function in R to compute these probabilities. In general, if \\(T\\sim t(\\nu)\\) then we compute \\(P(T &lt; t)\\) using pt(t, ν). So in this case:\n\npt(sqrt(10)/5, 9)\n\n[1] 0.7285895"
  },
  {
    "objectID": "jan22.html#quantile-functions",
    "href": "jan22.html#quantile-functions",
    "title": "Computing various probabiltiies in R",
    "section": "Quantile functions",
    "text": "Quantile functions\nIf \\(X\\) is a continuous random variable with cumulative distribution function \\(F_X\\), then its quantile function is \\(Q_X = F^{-1}_X\\). In particular,\n\\[P(X\\leq x) = p \\iff Q_X(p) = x.\\]\nIn R, we can compute quantile functions using functions beginning with q. Let’s work all of our previous examples backwards.\n\nqchisq(0.6999858, 5, lower.tail = FALSE)\n\n[1] 3\n\n\n\nqnorm(0.7364554)\n\n[1] 0.6324556\n\nsqrt(10)/5\n\n[1] 0.6324555\n\n\n\nqt(0.7285895, 9)\n\n[1] 0.6324555"
  }
]